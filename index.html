<!DOCTYPE html>
<html>
	<head>
	<meta name="generator" content="Hugo 0.74.3" />
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Christoph Heindl</title><link rel="apple-touch-icon" sizes="180x180" href="https://cheind.github.io/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="https://cheind.github.io/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="https://cheind.github.io/favicon-16x16.png">
	<link rel="manifest" href="https://cheind.github.io/site.webmanifest">
	<link rel="mask-icon" href="https://cheind.github.io/safari-pinned-tab.svg" color="#5bbad5">
	<meta name="msapplication-TileColor" content="#da532c">
	<meta name="theme-color" content="#ffffff">

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="https://cheind.github.io/index.xml" title="Christoph Heindl" />
	<meta property="og:title" content="Christoph Heindl" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://cheind.github.io/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Christoph Heindl"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://cheind.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://cheind.github.io/css/main.css"/>

	<script src="https://cheind.github.io/js/feather.min.js"></script><script src="https://cheind.github.io/js/main.js"></script>
</head>


	<body>
		<div class="container wrapper">
			<div class="header">
	<img src=https://cheind.github.io/profile.jpg class="profile_image">
	<h1 class="site-title">Christoph Heindl</h1>
	<span class="main-email">christoph.heindl@gmail.com</span>
	<nav class="nav social">
		<ul class="flat"><a href="https://github.com/cheind" title="GitHub"><i data-feather="github"></i></a><a href="https://linkedin.com/in/christoph-heindl/" title="LinkedIn"><i data-feather="linkedin"></i></a>
			|
			<a href="CV_cheind.pdf" class="blog_cv">[cv]</a>
			
			
		</ul>
	</nav>
	<div class="site-affilation">

		
	</div>

	<nav class="nav">
		<ul class="flat">
			
		</ul>
	</nav>
</div>

			<div class="introduction"><span>
		I am currently a research scientist at PROFACTOR working at the interface of computer vision and robotics. I received my doctoral degree (with distinction) from JKU in the field of computer vision and machine learning. My focus is on probabilistic approaches to create optimized artificial training data for machine learning.
	</span>
	<br><span>
		Recently, I created a widely used real-time 3D reconstruction software called <a href="https://www.reconstructme.net/">ReconstructMe</a> and initiated several popular <a href="https://github.com/cheind">open source projects</a>. These projects are now used by a variety of research groups worldwide, including Facebook, Google, and Microsoft.
	</span>
	<br><span>
		<b>Interests.</b> Machine Learning, Computer Vision, and Robotics.
	</span>
</div>
			
			<div class="introduction">
	
</div>

			<div class="introduction">
	</div>

			<div class="introduction">
	
    <h3 style="margin-top:1.5cm;">Academic Notes</h3>
    A collection of notes I have prepared in the past on various topics of interest.
	<ul>
		<li>
			<a href="" class="project"> Semi-supervised Expectation Maximization</a>

			
			<span class="code_blog">
				
				[<a href="notes/Notes_on_Semi_Supervised_Expectation_Maximization.pdf">pdf</a>]
				

				
				[<a href="notes/EM.ipynb">ipynb</a>]
				
			</span>
			

			
			<span class="project_description">
				This work considers the Expectation Maximization (EM) algorithm in the semi-supervised setting. First, the general form for semi-supervised version of maximum likelihood is derived from the Latent Variable Model (LVM). Since the involved integrals are usually intractable, a surrogate objective function based on the Evidence Lower Bound (ELBO) is introduced. Next, we derive the equations of the semisupervised EM. Finally, the concrete equations for a fitting a Gaussian Mixture Model (GMM) using labeled and unlabeled data are deduced.
			</span>
			

		</li>
		
		<li>
			<a href="" class="project"> Variational Autoencoders</a>

			
			<span class="code_blog">
				
				[<a href="notes/Notes_on_Variational_Autoencoders.pdf">pdf</a>]
				

				
				[<a href="notes/vae.zip">ipynb</a>]
				
			</span>
			

			
			<span class="project_description">
				We seek to perform density estimation between a true (but unknown) probability distribution, and a set of proposal distributions.  Formulated as minimization between distributions, this leads to the maximum (marginal) likelihood principle (see Section 2). To extend the expressiveness of our proposal distributions, we introduce latent variable models (see Section 3).  The hidden variables raise issues in evaluating the marginal likelihood.  We replace the marginal likelihood by a surrogate objective developed by Variational Inference (see Section 4).  Combining these ideas gives us a powerful framework to estimate marginal, inference and joint distributions simultaneously.  The Variational Autoencoder(see Section 5) is a specific application of these framework, that parametrizes the distributions to be optimized by neural networks.
			</span>
			

		</li>
		
		<li>
			<a href="" class="project"> Stochastic Optimization of Non-Differentiable Functions</a>

			
			<span class="code_blog">
				
				[<a href="notes/Notes_on_Stochastic_Optimization_for_BlendTorch.pdf">pdf</a>]
				

				
				[<a href="https://github.com/cheind/pytorch-blender">blendtorch</a>]
				
			</span>
			

			
			<span class="project_description">
				We consider a gradient based parameter optimization of a stochastic computational graph consisting of random scene properties and a deterministic, non-differentiable render function. Our approach leverages ideas from Generative Adverserial Networks (GANs) and gradient estimators from reinforcement learning to jointly optimize all distributional and structural parameters based on generated images. This document should be regarded as an unfinished notebook to emphasize our main idea.
			</span>
			

		</li>
		</ul>
	
</div>

		</div>
		</div>
		<div class="footer wrapper">
	<nav class="nav">
		<div>Christoph Heindl 2021</div>
	</nav>
</div>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-176158287-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script>
	feather.replace()
</script>
	</body>

</html>
